---
title: "CPH 565 Portfolio"
author: "Daniel B. Cooper"
categories: [code, analysis]
image: "image.png"
---

<font size="5"> Bayesian Biostatistics (Spring 2025) </font>

Table of Contents

- [Chapter 2](#chapter-2)
  - [Non-informative prior](#non-informative-prior)
  - [Highest Density Credible Interval](#highest-density-credible-interval)
- [Chapter 3](#chapter-3)
  - [Linear Regression](#linear-regression)
  - [Mahalanobis Distance](#mahalanobis-distance)
- [Chapter 5](#chapter-5)
  - [First Example](#first-example)
  - [Second Example](#second-example)
  - [Third Example](#third-example)
- [Chapter 6](#chapter-6)
- [Chapter 7](#chapter-7)
- [Bibliography](#bibliography)
- [Appendix](#appendix)
  - [Chapter 2](#chapter-2-1)
  - [Chapter 3](#chapter-3-1)
  - [Chapter 5](#chapter-5-1)
  - [Chapter 6](#chapter-6-1)
  - [Chapter 7](#chapter-7-1)


\newpage

## Chapter 2

### Non-informative prior

![](portfolio_full/non-informative-prior.png){width="300"}

The non-informative prior introduced to the example changed the curves. The prior line is now a flat horizontal line. This gives zero information to the calculation about the probability distrubution we might expect from the posterior distributions. For the small sample size, posterior uncertainty is large but resembles the density of the larger sample. A credible interval would take up almost the entire range of p. With just 15 more data points, the posterior distribution resembles the posterior distribution in the examples with realistic and unrealistic priors where n=20.

The non-informative prior highlights that sample size is even more important in reducing uncertainty since the data is the only driver for determining posterier distribution. Compared to the "bad" or unrealistic prior, the posterior distribution of the smaller sample size was actually closer to the larger sample size when using the non-informative prior. This may highlight why some statisticians would choose a non-informative prior to let the data drive the posterior uncertaintly since choosing an unrealistic prior chould be in disagreement with the data.

### Highest Density Credible Interval

The 95% highest posterior density credible interval for p, corresponding to the non-informative prior and the larger data set is: 0.06921215 \<= p \<= 0.3994838. There is a 95% probability that the true value of the parameter (probability of successful free throws) is between 0.069 and 0.399. I used both the Newton-Raphson method and the optimize() function in R to calcuate the narrowest interval.

![](portfolio_full/95_CI.png){width="300"}

\newpage

## Chapter 3

### Linear Regression

![](portfolio_full/linear-model.png){width="300"}

![](portfolio_full/linear-model-residuals.png){width="300"}

First, it seems from the fitted line that the model fits the data well. However; there are a few observations that stand out in both the scatter plot/fitted line plot and the residual plot. Visually, there are 3 points to me that are "far" from the fitted line in the first plot and have large residuals (far from 0) in the second plot. Let's look at a table with the observations with the largest residual values:

```{r}
#| label: tbl-linear-model
#| tbl-cap: "Top 5 residuals - Fitted Linear Model"
#| tbl-colwidths: [60,60]
#| echo: false

knitr::kable(head(dplyr::arrange(read.csv(here::here("posts/primary/portfolio_full/linear-model-data.csv")), dplyr::desc(abs_re)), 5))
```

First, the observation with x == 0.95 and y == -1.46 has a residual value of -4.11. Visually, that point seemed far from the fitted line to me in plot 1, and the residual checks out. Next, the observation with x == -0.82 and y == 1.63 has a residual value of 4.09. This also stood out to me as "far" from the fitted line in plot 1. You can see these as far from the horizontal line at 0 in the residual plot as well!

### Mahalanobis Distance

Based on the table above, we can see that the highest Mahalanobis Distance values co-occur with observations with high residual values. This makes sense! This Mahalanobis distance is based on an observation's distance from the mean vector, considering variance and covariance. This is similar to what the residual is showing in our basic example with one predictor and one response variable. From the plot below, the shape of the contour is very similar to the shape of the fitted line. In this simple example, values for Mahalnobis Distance and for absolute residual value are extremely similar.

![](portfolio_full/mdistance-plot.png){width="300"}

\newpage

## Chapter 5

### First Example

$p(\theta) \propto \sqrt{0.25 - (\theta - 0.5)^{2}}$

7 successes in 10 attempts

![](portfolio_full/BernGridExample1.png){width="300"}

In this example, there are two features: 1. A 'flat', non-informative prior and 2. a small sample size. Despite having a small sample size, the posterior distribution aligns almost exactly to the likelihood function. This alignment is due to the flat prior, which influenced the posterior very little.

\newpage

### Second Example

$p(\theta) \propto \sqrt{0.25 - (\theta - 0.5)^{2}}$

70 successes in 100 attempts

![](portfolio_full/BernGridExample2.png){width="300"}

In this example, the prior is still flat, like example 1. However, the sample size is much larger. The proportion of successes is the same, so the mode is the same in the likelihood function (and similar to the posterior). However, the larger sample size gives us a more precise estimate. The range of credible values is smaller, as is shown by the narrower highest density interval.

\newpage

### Third Example

$p(\theta) = 2\quad for \quad \left| \theta - 0.5 \right| \ge 0.25, \quad p(\theta) = 0 \quad otherwise$

50 successes in 100 attempts

![](portfolio_full/BernGridExample3.png){width="300"}

In example 3, we see a very specifc prior. The prior gives credibility to both low and high extreme values while giving zero credibility to center values of theta. The likelihood function based on the data is split 50/50 with a mode of 0.5. Most of the data lies within this middle point of theta. Despite the data showing this simple distribution, the prior has a major influence on the posterior distribution, completely changing what we might expect based on the likelihood function. Since we have a balance of success to failures in the data, we now see a bimodal distribution that follows the prior. We even see two HDI's, which are both very narrow. Notably too, the sample size being large did not spare the posterior distribution from the heavy influence of the prior.

\newpage

## Chapter 6

The following answers are in response to chapter 6 prompts regarding the article "An Introduction to Empirical Bayes Data Analysis" by George Casella (1985).

1.  A new hypothetical baseball player hitting an observed batting average of .267 would have a predicted final batting average of .277. This was calculated using the the formula in the footnote of Table 1: empirical Bayes estimate = .142 + .505 \* observed batting estimate.

2.  Predicting the final batting averages using a beta prior with parameters a and b:

    -   First, I'll calculate proportion of successes for each player using the formula round(45 \* observed batting average): 1. 18/45, 2. 16/45, 3. 14/45, 4. 13/45, 5. 11/45, 6. 10/45, 7. 8/45
    -   Mean of proportions: 0.2857; SD of proportions: 0.077: the standard deviation is less than 0.28867, so we can proceed (Kruschke, 2014; page 130).
    -   Using Kruschke's included utility function "betaABfromMeanSD," beta parameter a was found to be 9.438 and b was found to be 23.595.
    -   Using the formula: posterior mean = (numerator + a) / (denominator + a +b), the posterior means for each player are: .351, .326, .300, .288, .262, .249, and .223.
    -   These posterior means are very similar to the predictions from the empirical Bayes estimator used by Casella. They are notably closer to the actual final batting average than the classical estimator, so the benefit that Casella notes - that the Bayes estimator helps account for regression to the mean - may still hold with this calculation of posterior means from a beta prior.

3.  A beta prior with a \< 1 and b \< 1 may make sense for consumer intent data because it creates a distribution with a "U" shape. In this distribution, most probability density is nearest 0 and 1. Casella notes that the empirical Bayes estimator had great estimates, so the chosen U-shaped prior is a good approximation of the true prior distribution. I think that it also makes some intuitive sense that most people would skew toward extremes of intent rather than be undecided. Therefor, consumer intent is less likely to be in the middle of the distribution.

4.  Both sets of formulas (2.3 and 2.4 from Casella) and in the chapter 5b slides (Charnigo) are describing how to calculate posterior distributions. Both formulas use sample means and prior means as well as sample variance and prior variance. In the chapter 5b slides, we use weights related to the reciprocals of the prior and sample variance. Casella's formula does not seem to do that.

5.  In Casella's formula 2.7, when p = 3, the empirical Bayes estimate is equal to the sample estimate. When this occurs, result 2.8 cannot be true. Both sides of the comparison would be equal, so it is not possible that one is less than the other.

\newpage

## Chapter 7
### Results from edited "BernMetrop.R" (Kruschke)

![](portfolio_full/BernMetrop_cooper.png){width="300"}

Compared to the results obtained from the first example in Chapter 5, which used a grid/comb to approximate the posterior distribution, the results from the approximation using the Metropolis algorithm are very similar. The posterior mode for the grid approximation was 0.682 compared to the Metropolis approximation of 0.677. The 95% HDI is also very close to the same values. The resulting image from the edited Metropolis algorithm utility looks almost identical to the center column of the figure 7.4 image (Kruschke). Both are using the same Metropolis approximation, use a proposal standard deviation of 0.2, and have the same proportion of sucesses in the data. The difference found between the posterior distributions may be due to the larger sample size in the data used for figure 7.4 (14 successes in 20 attempts) versus the 7 successes in 10 attempts in the data used in the modified BernMetrop utility.

### Results from twice edited "BernMetrop.R" (Kruschke)

![](portfolio_full/BernMetrop_cooper2.png){width="300"}

The posterior mode in this edited version is similar with a difference of only about 0.01. The 95% HDI also sees very little change. The histogram bins seem to be less uniform after reducing the number of jumps to try. Now with fewer "jumps," the histogram is less smooth as there were fewer samples of theta available to report. We can see that the effective sample size is now only 993 versus the 9817 from before. We also see burn in complete much sooner (around 8 steps in chain) since burn in is dependent on the trajectory value/number of "jumps."

\newpage

## Bibliography

1.  Casella, G. (1985). An Introduction to Empirical Bayes Data Analysis. The American Statistician, 39(2), 83-. https://doi.org/10.2307/2682801
2.  Charnigo, R. (2024-2025). CPH 565 Course Content.
3.  Kruschke, J. (2014). Doing Bayesian Data Analysis, 2nd Edition. Academic Press.

\newpage

## Appendix

### Chapter 2

Acknowledgments: R code for the images created for chapter 2 was adapted from Dr. Charnigo's Chapter 2b examples. R code for calculating the 95% highest density CI was adapted from Dr. Charnigo's Chapter 3b Notes and from [math.arizona.edu/\~jwatkins/I4_bayes](https://math.arizona.edu/~jwatkins/I4_bayes.pdf)

Code:

```{r, echo = FALSE}
cat(readLines(here::here("posts/primary/portfolio_full/PortfolioChap2.r")), sep = "\n")

```

### Chapter 3

Acknowledgments: R code for completing chapter 3 portfolio contributions was adapted from Dr. Charnigo's Chapter 3a and 3b examples.

Code:

```{r, echo = FALSE}
cat(readLines(here::here("posts/primary/portfolio_full/PortfolioChap3.r")), sep = "\n")

```

### Chapter 5

Acknowledgments: Outputs for this chapter exercise were created using the "BernGrid.r" utility provided by John Kruschke (https://sites.google.com/site/doingbayesiandataanalysis/software-installation)

Code:

```{r, echo = FALSE}
cat(readLines(here::here("posts/primary/portfolio_full/PortfolioChap5.r")), sep = "\n")

```

### Chapter 6

Acknowledgments: Outputs for this chapter exercise were created using the betaABfromMeanSD function utility provided by John Kruschke (https://sites.google.com/site/doingbayesiandataanalysis/software-installation)

Code:

```{r, echo = FALSE}
cat(readLines(here::here("posts/primary/portfolio_full/PortfolioChap6.r")), sep = "\n")

```

### Chapter 7

Acknowledgments: Outputs for this chapter exercise were created using the BernMetrop.R utility provided by John Kruschke (https://sites.google.com/site/doingbayesiandataanalysis/software-installation)
